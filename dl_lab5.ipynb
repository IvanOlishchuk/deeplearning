{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "1. Make a tensor of size (2, 17)\n",
    "2. Make a torch.FloatTensor of size (3, 1)\n",
    "3. Make a torch.LongTensor of size (5, 2, 1)\n",
    "  - fill the entire tensor with 7s\n",
    "4. Make a torch.ByteTensor of size (5,)\n",
    "  - fill the middle 3 indices with ones such that it records [0, 1, 1, 1, 0]\n",
    "5. Perform a matrix multiplication of two tensors of size (2, 4) and (4, 2). Then do it in-place.\n",
    "6. Do element-wise multiplication of two randomly filled $(n_1,n_2,n_3)$ tensors. Then store the result in an Numpy array.\n",
    "\n",
    "### Forward-prop/backward-prop\n",
    "1. Create a Tensor that `requires_grad` of size (5, 5).\n",
    "2. Sum the values in the Tensor.\n",
    "3. Multiply the tensor by 2 and assign the result to a new python variable (i.e. `x = result`)\n",
    "4. Sum the variable's elements and assign to a new python variable\n",
    "5. Print the gradients of all the variables\n",
    "6. Now perform a backward pass on the last variable (NOTE: for each new python variable that you define, call `.retain_grad()`)\n",
    "7. Print all gradients again\n",
    "\n",
    "### Deep-forward NNs\n",
    "1. Use dl_lab2. In Exercise 12 there, you had to build an $L$-layer neural network with the following structure: *[LINEAR -> RELU]$\\times$(L-1) -> LINEAR -> SIGMOID*. Reimplement the manual code in PyTorch.\n",
    "2. Compare test accuracy using different optimizers: SGD, Adam, Momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) \n",
      " torch.float32 \n",
      " torch.Size([5, 2, 1])\n",
      "tensor([[[7],\n",
      "         [7]],\n",
      "\n",
      "        [[7],\n",
      "         [7]],\n",
      "\n",
      "        [[7],\n",
      "         [7]],\n",
      "\n",
      "        [[7],\n",
      "         [7]],\n",
      "\n",
      "        [[7],\n",
      "         [7]]])\n",
      "tensor([  0,   1,   1,   1, 205], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "tensor1 = torch.zeros(2, 17)\n",
    "tensor2 = torch.rand(3, 1, dtype=torch.float)\n",
    "tensor3 = torch.LongTensor(5,2,1)\n",
    "print(tensor1,'\\n', tensor2.dtype,'\\n', tensor3.shape)\n",
    "tensor3.fill_(7)\n",
    "print(tensor3)\n",
    "tensor4 = torch.ByteTensor(5,)\n",
    "tensor4[0]=0\n",
    "tensor4[1:4]=1\n",
    "print(tensor4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1067, 0.9209],\n",
      "        [1.1642, 1.2372]])\n",
      "tensor([[1.1067, 0.9209],\n",
      "        [1.1642, 1.2372]])\n"
     ]
    }
   ],
   "source": [
    "tensorA = torch.rand(2, 4)\n",
    "tensorB = torch.rand(4, 2)\n",
    "res = torch.matmul(tensorA, tensorB)\n",
    "print(res)\n",
    "res = torch.empty(2, 2)\n",
    "torch.matmul(tensorA, tensorB, out = res)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00713706, 0.6502601 , 0.03834382, 0.4092991 ],\n",
       "        [0.01113113, 0.47165358, 0.14229806, 0.28021   ],\n",
       "        [0.06600562, 0.25477883, 0.04627686, 0.29779077]],\n",
       "\n",
       "       [[0.02357975, 0.529625  , 0.06215126, 0.2055262 ],\n",
       "        [0.03677557, 0.38415322, 0.23065004, 0.14070515],\n",
       "        [0.2180725 , 0.2075127 , 0.07500987, 0.1495332 ]],\n",
       "\n",
       "       [[0.01297671, 0.05138903, 0.07086549, 0.35554573],\n",
       "        [0.02023881, 0.03727404, 0.26298952, 0.24340992],\n",
       "        [0.1200125 , 0.02013477, 0.08552703, 0.25868183]]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorA = torch.rand(3,1,4)\n",
    "tensorB = torch.rand(1,3,4)\n",
    "res = torch.mul(tensorA, tensorB)\n",
    "res = res.numpy()\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 tensor([[-0.8010, -0.1690,  0.3360,  0.7277, -0.1743],\n",
      "        [ 0.0911,  0.2875,  1.4629, -0.4733, -0.0430],\n",
      "        [ 1.6839,  0.9654,  0.8610, -0.3237,  0.6875],\n",
      "        [ 0.0566, -2.1928, -0.7458, -3.3702, -1.2937],\n",
      "        [-0.7990, -0.3539, -0.7029,  0.1029,  0.6222]], requires_grad=True)\n",
      "#2 tensor(-3.5578, grad_fn=<SumBackward0>)\n",
      "#3 tensor([[-1.6020, -0.3380,  0.6721,  1.4555, -0.3485],\n",
      "        [ 0.1822,  0.5749,  2.9258, -0.9467, -0.0859],\n",
      "        [ 3.3678,  1.9309,  1.7220, -0.6475,  1.3750],\n",
      "        [ 0.1132, -4.3855, -1.4917, -6.7404, -2.5873],\n",
      "        [-1.5979, -0.7078, -1.4059,  0.2058,  1.2443]], grad_fn=<MulBackward0>)\n",
      "#4 tensor(-7.1157, grad_fn=<SumBackward0>)\n",
      "#1  None \n",
      "#2  None \n",
      "#3  None \n",
      "#4  None\n",
      "#1  tensor([[2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.]]) \n",
      "#2  None \n",
      "#3  tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]]) \n",
      "#4  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "#pt2\n",
    "tensor = torch.randn(5,5, requires_grad = True) #1\n",
    "print('#1', tensor)\n",
    "sum_t = torch.sum(tensor) #2\n",
    "sum_t.retain_grad()\n",
    "print('#2', sum_t)\n",
    "mul_t = torch.mul(tensor, 2) #3\n",
    "mul_t.retain_grad()\n",
    "print('#3', mul_t)\n",
    "sum_t2 = torch.sum(mul_t) #4\n",
    "print('#4', sum_t2)\n",
    "sum_t2.retain_grad()\n",
    "\n",
    "print('#1 ', tensor.grad, '\\n#2 ', sum_t.grad, '\\n#3 ', mul_t.grad, '\\n#4 ', sum_t2.grad)\n",
    "sum_t2.backward()\n",
    "print('#1 ', tensor.grad, '\\n#2 ', sum_t.grad, '\\n#3 ', mul_t.grad, '\\n#4 ', sum_t2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt3\n",
    "def initialize_parameters_deep(layer_dims):\n",
    "    torch.manual_seed(42)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims) # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        #(≈ 2 lines of code)\n",
    "        # parameters['W' + str(l)] = ...\n",
    "        # parameters['b' + str(l)] = ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        parameters['W' + str(l)] = torch.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
    "        parameters['b' + str(l)] = torch.zeros((layer_dims[l], 1))\n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    # The for loop starts at 1 because layer 0 is the input\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        #(≈ 2 lines of code)\n",
    "        # A, cache = ...\n",
    "        # caches ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        A, cache = linear_activation_forward(A_prev,  parameters['W' + str(l)], parameters['b' + str(l)], 'relu')\n",
    "        caches.append(cache)\n",
    "        # YOUR CODE ENDS HERE\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    #(≈ 2 lines of code)\n",
    "    # AL, cache = ...\n",
    "    # caches ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    AL, cache = linear_activation_forward(A,  parameters['W' + str(L)], parameters['b' + str(L)], 'sigmoid')\n",
    "    caches.append(cache)\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a deep convolutional neural network using PyTorch\n",
    "\n",
    "### The multilayer CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "Image(filename='figures/14_12.png', width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision \n",
    "from torchvision import transforms \n",
    "image_path = './'\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "mnist_dataset = torchvision.datasets.MNIST(root=image_path, \n",
    "                                           train=True, \n",
    "                                           transform=transform, \n",
    "                                           download=True)\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "mnist_valid_dataset = Subset(mnist_dataset, torch.arange(10000)) \n",
    "mnist_train_dataset = Subset(mnist_dataset, torch.arange(10000, len(mnist_dataset)))\n",
    "mnist_test_dataset = torchvision.datasets.MNIST(root=image_path, \n",
    "                                           train=False, \n",
    "                                           transform=transform, \n",
    "                                           download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(mnist_train_dataset, batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(mnist_valid_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a CNN using the torch.nn module\n",
    "\n",
    "#### Configuring CNN layers in PyTorch\n",
    "\n",
    " * **Conv2d:** `torch.nn.Conv2d`\n",
    "   * `out_channels`\n",
    "   * `kernel_size`\n",
    "   * `stride`\n",
    "   * `padding`\n",
    "   \n",
    "   \n",
    " * **MaxPool2d:** `torch.nn.MaxPool2d`\n",
    "   * `kernel_size`\n",
    "   * `stride`\n",
    "   * `padding`\n",
    "   \n",
    "   \n",
    " * **Dropout** `torch.nn.Dropout`\n",
    "   * `p`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a CNN in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "model = nn.Sequential()\n",
    "model.add_module('conv1', nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2))\n",
    "model.add_module('relu1', nn.ReLU())        \n",
    "model.add_module('pool1', nn.MaxPool2d(kernel_size=2))   \n",
    "model.add_module('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2))\n",
    "model.add_module('relu2', nn.ReLU())        \n",
    "model.add_module('pool2', nn.MaxPool2d(kernel_size=2))      \n",
    "\n",
    "x = torch.ones((4, 1, 28, 28))\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_module('flatten', nn.Flatten()) \n",
    "\n",
    "x = torch.ones((4, 1, 28, 28))\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_module('fc1', nn.Linear(3136, 1024)) \n",
    "model.add_module('relu3', nn.ReLU()) \n",
    "model.add_module('dropout', nn.Dropout(p=0.5)) \n",
    "\n",
    "model.add_module('fc2', nn.Linear(1024, 10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "model = model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, num_epochs, train_dl, valid_dl):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            x_batch = x_batch.to(device) \n",
    "            y_batch = y_batch.to(device) \n",
    "            pred = model(x_batch)\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
    "            is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
    "            accuracy_hist_train[epoch] += is_correct.sum().cpu()\n",
    "\n",
    "        loss_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                x_batch = x_batch.to(device) \n",
    "                y_batch = y_batch.to(device) \n",
    "                pred = model(x_batch)\n",
    "                loss = loss_fn(pred, y_batch)\n",
    "                loss_hist_valid[epoch] += loss.item()*y_batch.size(0) \n",
    "                is_correct = (torch.argmax(pred, dim=1) == y_batch).float() \n",
    "                accuracy_hist_valid[epoch] += is_correct.sum().cpu()\n",
    "\n",
    "        loss_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        accuracy_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        \n",
    "        print(f'Epoch {epoch+1} accuracy: {accuracy_hist_train[epoch]:.4f} val_accuracy: {accuracy_hist_valid[epoch]:.4f}')\n",
    "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid\n",
    "\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 20\n",
    "hist = train(model, num_epochs, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x_arr = np.arange(len(hist[0])) + 1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, hist[0], '-o', label='Train loss')\n",
    "ax.plot(x_arr, hist[1], '--<', label='Validation loss')\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Loss', size=15)\n",
    "ax.legend(fontsize=15)\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, hist[2], '-o', label='Train acc.')\n",
    "ax.plot(x_arr, hist[3], '--<', label='Validation acc.')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Accuracy', size=15)\n",
    "\n",
    "#plt.savefig('figures/14_13.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.synchronize()\n",
    "model_cpu = model.cpu()\n",
    "pred = model(mnist_test_dataset.data.unsqueeze(1) / 255.)\n",
    "is_correct = (torch.argmax(pred, dim=1) == mnist_test_dataset.targets).float()\n",
    "print(f'Test accuracy: {is_correct.mean():.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 4))\n",
    "for i in range(12):\n",
    "    ax = fig.add_subplot(2, 6, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    img = mnist_test_dataset[i][0][0, :, :]\n",
    "    pred = model(img.unsqueeze(0).unsqueeze(1))\n",
    "    y_pred = torch.argmax(pred)\n",
    "    ax.imshow(img, cmap='gray_r')\n",
    "    ax.text(0.9, 0.1, y_pred.item(), \n",
    "            size=15, color='blue',\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center', \n",
    "            transform=ax.transAxes)\n",
    "    \n",
    "    \n",
    "#plt.savefig('figures/14_14.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "\n",
    "path = 'models/mnist-cnn.ph'\n",
    "torch.save(model, path)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
